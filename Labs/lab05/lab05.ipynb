{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\" # put your full name here\n",
    "COLLABORATORS = [] # list anyone you collaborated with on this workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 5: Least Squares Regression (Single-Variable)\n",
    "**This lab was distributed the week of September 28, 2020 and should be completed by Tuesday, October 6, 2020 at 11:59PM Pacific.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to your fifth lab of the semester!<br>\n",
    "\n",
    "This lab aims to get you started with linear regression in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction and Data Source\n",
    "In lecture we went over formulas to solve for the coefficients $\\beta_0$ and $\\beta_1$ in a single-variable least squares regression problem:\n",
    "\n",
    "$y_i = \\beta_0 + \\beta_1 x_i + e_i$.\n",
    "\n",
    "Those formulas are:\n",
    "\n",
    "$\n",
    "\\hat{\\beta}_0  =\\bar{y} - \\hat{\\beta}_1\\bar{x}\\\\\n",
    "\\hat{\\beta}_1 = \\frac{ \\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})}{\\sum_{i=1}^n (x_i-\\bar{x})^2}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we'll be applying least squares regression to data from the [California Department of Transportation (CalTrans)](https://data.ca.gov/dataset/caltrans-annual-vehicle-delay). \n",
    "\n",
    "**Question 1:** Load in the .csv file in the \"data\" folder and save it to a dataframe `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# df = ...\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset reports freeway congestion in California, organized by county and route. For this exercise, we'll be looking specifically at the Annual Vehicle Miles Traveled (VMT) field, which represents the total number of miles traveled per vehicle on that route in that county, and the Incidents/ Day field, which represents the average number of traffic incidents per day for that route and county in 2017.\n",
    "\n",
    "Let's create a model to predict the number of Incidents/Day (i.e., the target variable) as a function of annual VMT (i.e., the independent variable). \n",
    "\n",
    "**Question 2:** To start off with, create a scatter plot with Annual VMT on the x-axis and Incidents/Day on the y-axis. What can you say about the general relationship between these two variables?\n",
    "\n",
    "*Note*: instead of typing out a long column name everytime you need to use it, you can create a variable that contains that column name as a string. For instance, rather than typing out `df[\"Annual Vehicle Miles Traveled (VMT)\"]`, you can define a variable `vmt`:\n",
    "```python\n",
    "vmt = \"Annual Vehicle Miles Traveled (VMT)\"\n",
    "df[vmt]\n",
    "```\n",
    "You can also just re-name the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your observations here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate the coefficients\n",
    "**Question 3:** Write a function that returns the estimated $\\beta_0$ and $\\beta_1$ using the summation formulas from class (i.e., the formulas above in the lab notebook), taking the vectors of all $x$ and $y$ observations as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# def get_betas(x,y):\n",
    "#     # YOUR CODE HERE\n",
    "#     return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4:** Use your function to estimate $\\beta_0$ and $\\beta_1$ for the independent and response variables of interest in the Caltrans data you loaded.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # YOUR CODE HERE\n",
    "# print('Beta values are', b0, 'and', b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the target (dependent) variable\n",
    "\n",
    "**Question 5:** Use your estimated coefficients to predict Incidents/Day ($\\hat{y}$) for every observation of annual VMT ($x_i$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat =  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(y_hat) == len(df) # Your code should return a predicted value of y for every observation in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6:** Output a plot that overlays your regression line on a scatterplot of VMT vs. incidents per day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model estimation and prediction using sckit tools\n",
    "\n",
    "We can (and will) also estimate coefficients and predict response variables using the Python package scikit-learn. As we move forward in this class, we will be developing more complicated models and using more than one independent variable. The scikit-learn toolbox gives us a way to run regression (and other!) models quickly and efficiently. Let's walk through an example using single-variable regression.\n",
    "\n",
    "First, we need to set up some new dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install sklearn\n",
    "! pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `scikit-learn` package has a `linear_model` object upon which you can call `LinearRegression()` to generate a linear regression object:\n",
    "\n",
    "`lm = linear_model.LinearRegression()`\n",
    "\n",
    "`lm` takes as arguments to its `.fit()` method the arrays $X$ and $y$, where $X$ is a dataframe of independent variables and $y$ is a dataframe of the dependent variable, or our \"target\" data.\n",
    "\n",
    "*Note*: The `scikit-learn` functions will only accept $X$ and $y$ as inputs if both dimensions of these arrays' respective shapes are explicitly defined. In other words, if $X$ and/or $y$ is one-dimensional, the `linear_model` functions will produce errors if either of these arrays has a `shape` of the form `(n,)`, where n is the number of elements in the array. Instead, one-dimensional arrays need to be reformatted to have the shape `(n,1)`. You'll have to get the values from your panda dataframe for $X$ and $y$, and then use the `.reshape()` method to get the right dimensions. Alternatively, `scikit-learn` will also accept an input if it takes the form of a pandas dataframe rather than a pandas series; for example, defining $X$ as `df[['column_name']]` is acceptable in `scikit-learn` syntax, but defining $X$ as `df['column name']` is not.\n",
    "\n",
    "For example, we would initiate and fit a linear regression model for the CalTrans data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[vmt]] # define an array of independent variables\n",
    "y = df[[i_day]] # define an array (usually one-dimension) of target variables\n",
    "lm_incidents = linear_model.LinearRegression() # initiate a linear regression object\n",
    "fit_incidents = lm_incidents.fit(X,y) # fit the linear regression object to your X and y data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above, the `.fit()` method estimates the coefficients for our linear model. We can access the coefficients $\\hat{\\beta}_0$ and $\\hat{\\beta}_1$ as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta0_hat =  fit_incidents.intercept_\n",
    "beta1_hat = fit_incidents.coef_\n",
    "print('beta0_hat:', beta0_hat)\n",
    "print('beta1_hat:', beta1_hat) # If we had more than one x term, .coef_ would return more than one coefficient, i.e., beta1_hat, beta2_hat..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7:** How do the estimates of $\\hat{\\beta}_0$ and $\\hat{\\beta}_1$ that we found using the `scikit-learn` tools compare to those we found using the linear regression equations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use `scikit-learn` to predict the target variable. The `linear_model` object we initated and fit for the CalTrans data has a `.predict()` method, which takes in a matrix $X$ and returns a list of $\\hat{y}$ values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = fit_incidents.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the values for y_pred equal the values for y_hat, at least the the 8th decimal place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (np.round(y_pred,8) == np.round(y_hat.values.reshape(-1,1),8)).all() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model performance (the cost function)\n",
    "\n",
    "**Question 8:** Using the `y_hat` predicted values you developed in Question 5, calculate the error term $e_i$ (aka, the residual) for each pair of predictions and observations. The result for `error` should be a 1-dimensional array that has the same length as our number of observations. Then, create a scatter plot with the residual on the y-axis and Annual VMT on the x-axis. Overlay on your plot a dotted horizontal line that crosses the y-axis at zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE\n",
    "\n",
    "error = ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 9:** Visually inspect your residual plot. Are there any regions of the x-domain in which your model seems to be systematically over- or under-estimating the response variable? Is this a sign of variance or bias in your model, and what is one strategy for correcting this issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 10:** Calculate the mean square error (MSE) for your model using the formula below. Your result should be a single, non-negative value.\n",
    "\n",
    "$\n",
    "MSE  =\\frac{1}{n} \\sum_{i=1}^n e_i^2\n",
    "$\n",
    "\n",
    "*Hint:* Use the `error` array you created in Question 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "MSE = ...\n",
    "print(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can use scikit-learn built-in functions to calculate MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = mean_squared_error(df[i_day], y_hat)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into testing and training subsets\n",
    "In the previous few questions, we didn't divide our data into training and testing sets - we fit the regression line to the full dataset, and tested its performance on that same full dataset. In this section we'll build a loop that splits our data into a testing and a training set and then creates and evaluates a model for each training set. \n",
    "\n",
    "As an optional (commented out) exercise, you can also examine the 95% confidence intervals for the beta coefficients we develop for each test/train iteration. To do that, you'll need some functions to estimate the residual standard error (RSE) and the standard error for $\\beta_0$ and $\\beta_1$. Recall the following formulas from ISLR:\n",
    "\n",
    "$\n",
    "RSE = \\sqrt{(n-2)^{-1} * \\sum_{i=1}^n e_i^2}\\\\\n",
    "SE(\\hat{\\beta}_0)^2  = RSE^2 [\\frac{1}{n} + \\frac {x^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2}]\\\\\n",
    "SE(\\hat{\\beta}_1)^2 = \\frac{RSE^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2}\n",
    "$ \n",
    "\n",
    "Luckily, we can adapt the functions Duncan developed for the asynchronous lectures to calculate RSE and the standard errors of the beta coefficients. In the code below, `e_array` is an array of residuals (errors), `n` is the number of observations, and `x` is the array of independent variable observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResidSE(e_array):\n",
    "    return np.sqrt(np.sum(e_array**2)/(len(e_array)-2))\n",
    "\n",
    "def StandErr_b0(RSE, n, x):\n",
    "    xbar = np.mean(x)\n",
    "    return np.sqrt(RSE**2*(1/n + xbar**2/np.sum((x - xbar)**2)))\n",
    "\n",
    "def StandErr_b1(RSE, n, x):\n",
    "    xbar = np.mean(x)\n",
    "    return np.sqrt(RSE**2*(1/np.sum((x - xbar)**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 11:** Using the functions above, create a loop that does the following 100 times:\n",
    "\n",
    "1 - Randomly selects the training data from the full dataset<br>\n",
    "2 - Estimates the beta values of the training set, using the `get_beta` function you've defined<br>\n",
    "3 - Tests the model performance (by calculating MSE) against the testing data<br>\n",
    "4 - [Optional] Computes the residual standard error, standard error, and 95% confidence intervals for the estimated beta values<br>\n",
    "\n",
    "For each iteration through the loop, we'll save the beta values, the error array, and the MSE (as well as the standard error, and the confidence intervals if you do the optional exercise). The skeleton code below will get you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the parameters for number of iterations and size of the testing and training sets\n",
    "n_iter = 100 # number of iterations\n",
    "n_train = int(np.round(len(df[vmt])*0.7)) # number of training data points is equal to 70% of the observations, rounded to the nearest integer\n",
    "n_test = int(len(df[vmt]) - n_train) # number of testing data points\n",
    "\n",
    "# initialize a bunch of arrays populated with np.nan to store various output values produced during each iteration\n",
    "betas = np.full((n_iter,2),np.nan) # each row will contain the estimated b0 and b1 for each test/train iteration\n",
    "error = np.full((n_iter, n_test),np.nan) # each row will contain the error values associated with the testing dataset for a given test/train iteration\n",
    "MSE = np.full(n_iter, np.nan) # each value will be the mean squared error for a given test/train iteration\n",
    "RSE = np.full(n_iter, np.nan) # each value will be the residual standard error for a given test/train iteration\n",
    "\n",
    "## Optional\n",
    "# SEb0 = np.full(n_iter, np.nan) # each value is the standard error of estimated b0 for a given test/train iteration\n",
    "# SEb1 = np.full(n_iter, np.nan) # each value is the standard error of estimated b1 for a given test/train iteration \n",
    "# CIb0 = np.full((n_iter,2),np.nan) # each row holds the upper and lower bounds for the 95% confidence interval of b0 for a given test/train iteration \n",
    "# CIb1 = np.zeros((n_iter,2)) # each row holds the upper and lower bounds for the 95% confidence interval of b1 for a given test/train iteration \n",
    "\n",
    "\n",
    "for i in range(n_iter):\n",
    "    train_indx = np.random.choice(len(df[vmt]), size = n_train, replace = False)\n",
    "    test_indx = np.setdiff1d(np.arange(len(df[vmt])),train_indx)\n",
    " \n",
    "    \n",
    "    # compute b0 and b1\n",
    "    betas[i,:] = ... # YOUR CODE HERE\n",
    "    \n",
    "    # estimate y_hat for every observation in the test dataset\n",
    "    y_hat = ... # YOUR CODE HERE\n",
    "    \n",
    "    # compute the MSE\n",
    "    e_array = ... # YOUR CODE HERE\n",
    "    error[i,:] = ... # YOUR CODE HERE\n",
    "\n",
    "    MSE[i] = ... # YOUR CODE HERE\n",
    "    \n",
    "\n",
    "    ## Optional\n",
    "#     # compute the residual standard error (required for computing coefficient S.E.)\n",
    "#     RSE[i] = ...\n",
    "    \n",
    "#     # compute coefficient S.E.\n",
    "#     SEb0[i] = ... \n",
    "#     SEb1[i] = ...\n",
    "    \n",
    "#     # compute 95% confidence intervals.\n",
    "#     CIb0[i,:] = ...\n",
    "#     CIb1[i,:] = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 12:** Plot two KDE distributions, one for each coefficient $\\hat{\\beta}_0$ and $\\hat{\\beta}_1$. Using `sns.kdeplot()` and label your plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the KDE plot for b0\n",
    "plt.subplot(2,1,1)\n",
    "... #YOUR CODE HERE\n",
    "\n",
    "\n",
    "#Plot the KDE plot for b1\n",
    "plt.subplot(2,1,2)\n",
    "... #YOUR CODE HERE\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "**Question 13** Plot a distribution of your mean squared error using `sns.kdeplot()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 14:** What do you notice about the KDE distributions for $\\hat{\\beta}_0$, $\\hat{\\beta}_1$, and MSE? Can you explain their shapes, based on what you've observed about the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 15:** Plot a scatter plot of all observations, overlayed with all 100 linear regression lines. We can plot the regression lines by using the array `betas` to calculate their value at two points, 0 and the maximum $x$ value (`df[vmt].max()`) - the skeleton code below gets you started by defining those two $x$ values. Play around with the linestyles, scatter plot marker sizes, and linewidths to get a legible plot. How do the regression lines relate to the KDE plots you created in Question 12?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "x = np.array([0, df[vmt].max()]) # two x values, at which y_hat can be calculated\n",
    "\n",
    "plt.figure(figsize = (10,5))\n",
    "\n",
    "plt.scatter(...)\n",
    "\n",
    "for i in range(n_iter):\n",
    "    y_hat = ...\n",
    "    plt.plot(...)\n",
    "    \n",
    "plt.title(...)\n",
    "plt.xlabel(...)\n",
    "plt.ylabel(...)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hooray, you're done! \n",
    "\n",
    "Please remember to submit your lab work, after clicking Kernel -> Restart & Run All, in .html and .ipynb format on bCourses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
